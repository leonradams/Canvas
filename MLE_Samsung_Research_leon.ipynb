{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MLE@Samsung_Research_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVRNjM2i5NPK"
      },
      "source": [
        "# Today you are a MLE@Samsung Research and your goal is to perform segmentation of cystic regions from OCT images.\n",
        "## This work is based on the recent publication https://arxiv.org/abs/2008.02952\n",
        "## This model is adapted from the original codebase in https://github.com/sohiniroych/U-net_using_TF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qF1HfB5NPO"
      },
      "source": [
        "# Optical Coherence Tomography (OCT) images represent grayscale images representing the depth of retina. Cystic regions are gaps in the retina as shown below\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "## Yor goal is to segment the cysts (dark gaps) in the images using the U-net model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHyaC_Hz5NPP"
      },
      "source": [
        "# Your Deliverables are as follows:\n",
        "### 1. Train a u-net model from scratch and test performance on test images for 2 OCT repos.\n",
        "### 2. Vary the loss function, kernel dialation, depthwise separable kernels and report results.\n",
        "### 3. Report observations with and without Batch normalization and Dropout at test time.\n",
        "### 4. If you use Dropout at test time and generate 2-3 test predictions, what do you observe from these predictions? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XNPYosbAOPi",
        "outputId": "b083ccee-a9fe-4c50-a5d1-bd684cf30670"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czRfS-MXAOTz",
        "outputId": "92bb01b5-726c-4285-f8e5-5162b9ed4571"
      },
      "source": [
        "%cd gdrive/MyDrive/'Colab Notebooks'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGMBgF545NPP"
      },
      "source": [
        "# Task 1: Implement U-net model from scratch for the 'cirrus_3' data set. Report performance on test set and save the model as 'unet_cirrus.hdf5'\n",
        "## [Instructor Led]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdn32kU55NPQ"
      },
      "source": [
        "## Lets start by stepwise defining all libraries and functions needed to generate the model and pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkKOprxX5NPQ"
      },
      "source": [
        "#Step 1: Load libraries for the U-net Model\n",
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "#from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtXktEYu5NPQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc as sc"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PAKeXh5NPR"
      },
      "source": [
        "#Define Additional loss functions for Task 2\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = keras.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = keras.sum(y_true, axis=[1,2,3]) + keras.sum(y_pred, axis=[1,2,3])\n",
        "    return keras.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ5YVKi95NPR"
      },
      "source": [
        "#Step 2: Define the U-net model\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = tf.keras.Input(shape=input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n",
        "    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    #[Try removing BatchNormalization and see performance]\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    \n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    \n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    \n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "   \n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n",
        "    \n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel=keras.models.load_model(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9JrYIq15NPS"
      },
      "source": [
        "#All additional functions for data prep and evaluation are housed in unet_helper_finctions.py\n",
        "from unet_helper_functions import *"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6IiB_mY5NPS"
      },
      "source": [
        "## All definitions are now done! Lets start using the functions now...\n",
        "## B. Call to image data generator, model initialization, followed by model fitting.\n",
        "\n",
        "__You can use the following code to unzip Data if you haven't done so__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7M8l4woSSNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c897d3-e5f5-43ac-be1c-513a3353902a"
      },
      "source": [
        "!unzip Data.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Data.zip\n",
            "   creating: Data/\n",
            "   creating: Data/cirrus_3/\n",
            "   creating: Data/cirrus_3/train/\n",
            "   creating: Data/cirrus_3/train/Image/\n",
            "  inflating: Data/cirrus_3/train/Image/bscan_100.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_101.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_102.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_103.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_104.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_122.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_105.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_106.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_107.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_108.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_109.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_110.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_111.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_112.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_113.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_114.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_115.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_116.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_117.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_118.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_119.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_120.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_121.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_123.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_124.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_125.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_126.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_127.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_128.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_129.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_130.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_131.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_132.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_133.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_134.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_135.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_136.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_137.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_138.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_139.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_140.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_141.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_142.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_143.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_144.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_145.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_146.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_147.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_148.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_149.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_59.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_60.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_61.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_62.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_63.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_64.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_65.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_66.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_67.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_68.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_69.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_70.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_71.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_72.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_73.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_74.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_75.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_76.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_77.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_78.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_79.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_80.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_81.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_82.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_83.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_84.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_85.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_86.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_87.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_88.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_89.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_90.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_91.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_92.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_93.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_94.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_95.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_96.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_97.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_98.jpg  \n",
            "  inflating: Data/cirrus_3/train/Image/bscan_99.jpg  \n",
            "   creating: Data/cirrus_3/train/GT/\n",
            "  inflating: Data/cirrus_3/train/GT/bscan_100.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_101.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_102.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_103.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_104.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_122.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_105.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_106.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_107.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_108.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_109.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_110.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_111.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_112.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_113.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_114.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_115.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_116.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_117.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_118.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_119.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_120.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_121.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_123.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_124.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_125.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_126.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_127.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_128.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_129.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_130.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_131.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_132.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_133.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_134.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_135.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_136.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_137.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_138.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_139.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_140.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_141.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_142.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_143.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_144.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_145.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_146.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_147.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_148.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_149.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_59.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_60.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_61.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_62.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_63.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_64.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_65.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_66.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_67.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_68.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_69.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_70.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_71.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_72.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_73.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_74.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_75.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_76.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_77.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_78.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_79.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_80.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_81.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_82.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_83.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_84.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_85.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_86.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_87.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_88.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_89.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_90.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_91.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_92.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_93.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_94.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_95.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_96.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_97.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_98.jpg  \n",
            "  inflating: Data/cirrus_3/train/GT/bscan_99.jpg  \n",
            "   creating: Data/cirrus_3/test/\n",
            "   creating: Data/cirrus_3/test/Image/\n",
            "  inflating: Data/cirrus_3/test/Image/bscan_150.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_151.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_152.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_153.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_154.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_155.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_156.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_157.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_158.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_159.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_160.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_161.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_162.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_163.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_164.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_165.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_166.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_167.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_168.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_169.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_170.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_171.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_172.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_173.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_174.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_175.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_176.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_177.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_178.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_179.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_180.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_181.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_182.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_183.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_184.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_185.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_186.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_188.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_189.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_190.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_191.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_192.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_193.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_194.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_195.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_196.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_199.jpg  \n",
            "  inflating: Data/cirrus_3/test/Image/bscan_200.jpg  \n",
            "   creating: Data/cirrus_3/test/GT/\n",
            "  inflating: Data/cirrus_3/test/GT/bscan_150.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_151.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_152.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_153.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_154.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_155.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_156.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_157.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_158.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_159.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_160.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_161.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_162.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_163.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_164.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_165.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_166.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_167.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_168.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_169.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_170.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_171.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_172.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_173.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_174.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_175.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_176.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_177.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_178.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_179.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_180.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_181.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_182.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_183.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_184.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_185.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_186.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_188.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_189.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_190.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_191.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_192.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_193.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_194.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_195.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_196.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_199.jpg  \n",
            "  inflating: Data/cirrus_3/test/GT/bscan_200.jpg  \n",
            "   creating: Data/nidek_1/\n",
            "   creating: Data/nidek_1/train/\n",
            "   creating: Data/nidek_1/train/Image/\n",
            "  inflating: Data/nidek_1/train/Image/bscan_125.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_126.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_34.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_39.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_40.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_89.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_35.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_36.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_37.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_41.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_42.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_43.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_44.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_45.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_46.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_47.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_48.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_49.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_50.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_51.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_52.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_53.jpg  \n",
            "  inflating: Data/nidek_1/train/Image/bscan_54.jpg  \n",
            "   creating: Data/nidek_1/train/GT/\n",
            "  inflating: Data/nidek_1/train/GT/bscan_125.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_126.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_34.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_39.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_40.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_89.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_35.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_36.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_37.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_41.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_42.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_43.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_44.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_45.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_46.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_47.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_48.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_49.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_50.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_51.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_52.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_53.jpg  \n",
            "  inflating: Data/nidek_1/train/GT/bscan_54.jpg  \n",
            "   creating: Data/nidek_1/test/\n",
            "   creating: Data/nidek_1/test/Image/\n",
            "  inflating: Data/nidek_1/test/Image/bscan_55.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_56.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_57.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_58.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_59.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_60.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_61.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_62.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_63.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_64.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_65.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_66.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_67.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_68.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_69.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_70.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_71.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_72.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_73.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_74.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_75.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_76.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_77.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_78.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_79.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_80.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_81.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_82.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_83.jpg  \n",
            "  inflating: Data/nidek_1/test/Image/bscan_90.jpg  \n",
            "   creating: Data/nidek_1/test/GT/\n",
            "  inflating: Data/nidek_1/test/GT/bscan_55.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_56.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_57.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_58.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_59.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_60.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_61.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_62.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_63.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_64.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_65.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_66.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_67.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_68.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_69.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_70.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_71.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_72.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_73.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_74.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_75.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_76.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_77.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_78.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_79.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_80.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_81.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_82.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_83.jpg  \n",
            "  inflating: Data/nidek_1/test/GT/bscan_90.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGe5uZ9F5NPS"
      },
      "source": [
        "#Step 1: Call to image data generator in keras\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=[0.7,1],\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "PATH='./Data/cirrus_3/train/'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecWnWjOy5NPT"
      },
      "source": [
        "if not os.path.exists(PATH+'aug'):\n",
        "    os.makedirs(PATH+'aug')\n",
        "    \n",
        "if not os.path.exists('./Data/cirrus_3/test/'+'pred'):\n",
        "    os.makedirs('./Data/cirrus_3/test/'+'pred')\n",
        "\n",
        "# the trainGenerator function is defined in the helpers file  \n",
        "data_gen = trainGenerator(10,PATH,'Image','GT',data_gen_args, save_to_dir = PATH+'aug')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnEYX-f55NPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1954a3f2-4a95-4bd1-d798-311f4607b129"
      },
      "source": [
        "#Step 2: Initialize the model. Train from scratch!\n",
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 512)  2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 512)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 1024) 4096        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 1024) 4096        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_5[0][0]      \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           batch_normalization_3[0][0]      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 256, 256, 1)  3           conv2d_22[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,047,557\n",
            "Trainable params: 31,039,621\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWoJT47d5NPU"
      },
      "source": [
        "#Step 3: Initialize Tensorboard to monitor changes in Model Loss \n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "# if you don't have the logs folder, make sure you create one:\n",
        "if not os.path.exists(PATH+'aug'):\n",
        "    os.makedirs('logs/fit/')\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo61qHZk5NPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d245930-1113-4eb7-8843-52b4e9fb6075"
      },
      "source": [
        "#Step 4: Fit the u-net model\n",
        "#model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1)#callbacks=[tensorboard_callback])\n",
        "# you can load the saved model using:\n",
        "# model.load_weights('unet_cirrus.hdf5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 91 images belonging to 1 classes.\n",
            "Found 91 images belonging to 1 classes.\n",
            "Epoch 1/50\n",
            "15/15 [==============================] - 89s 3s/step - loss: 0.1551 - accuracy: 0.9454\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 10s 656ms/step - loss: 0.0712 - accuracy: 0.9712\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 11s 695ms/step - loss: 0.0610 - accuracy: 0.9747\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 10s 667ms/step - loss: 0.0552 - accuracy: 0.9779\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 11s 729ms/step - loss: 0.0530 - accuracy: 0.9786\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 10s 683ms/step - loss: 0.0509 - accuracy: 0.9792\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 12s 736ms/step - loss: 0.0483 - accuracy: 0.9800\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 11s 716ms/step - loss: 0.0464 - accuracy: 0.9810\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 12s 772ms/step - loss: 0.0453 - accuracy: 0.9811\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 11s 739ms/step - loss: 0.0480 - accuracy: 0.9800\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 12s 793ms/step - loss: 0.0448 - accuracy: 0.9812\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 11s 721ms/step - loss: 0.0453 - accuracy: 0.9808\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 12s 752ms/step - loss: 0.0436 - accuracy: 0.9816\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 11s 707ms/step - loss: 0.0448 - accuracy: 0.9812\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 12s 772ms/step - loss: 0.0430 - accuracy: 0.9819\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 11s 719ms/step - loss: 0.0471 - accuracy: 0.9801\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 12s 774ms/step - loss: 0.0452 - accuracy: 0.9812\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 11s 727ms/step - loss: 0.0423 - accuracy: 0.9820\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 12s 776ms/step - loss: 0.0406 - accuracy: 0.9828\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 11s 717ms/step - loss: 0.0439 - accuracy: 0.9816\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 12s 762ms/step - loss: 0.0436 - accuracy: 0.9815\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 11s 714ms/step - loss: 0.0404 - accuracy: 0.9830\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 12s 766ms/step - loss: 0.0388 - accuracy: 0.9835\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 11s 718ms/step - loss: 0.0424 - accuracy: 0.9822\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 12s 770ms/step - loss: 0.0385 - accuracy: 0.9837\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 11s 720ms/step - loss: 0.0390 - accuracy: 0.9836\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 12s 769ms/step - loss: 0.0363 - accuracy: 0.9848\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 11s 716ms/step - loss: 0.0411 - accuracy: 0.9827\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 12s 774ms/step - loss: 0.0403 - accuracy: 0.9833\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 11s 719ms/step - loss: 0.0398 - accuracy: 0.9833\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 12s 765ms/step - loss: 0.0405 - accuracy: 0.9832\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 11s 724ms/step - loss: 0.0394 - accuracy: 0.9833\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 12s 773ms/step - loss: 0.0375 - accuracy: 0.9841\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 11s 717ms/step - loss: 0.0354 - accuracy: 0.9850\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 12s 766ms/step - loss: 0.0361 - accuracy: 0.9847\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 11s 720ms/step - loss: 0.0346 - accuracy: 0.9853\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 12s 771ms/step - loss: 0.0361 - accuracy: 0.9850\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 11s 719ms/step - loss: 0.0387 - accuracy: 0.9842\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 12s 763ms/step - loss: 0.0360 - accuracy: 0.9847\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 11s 717ms/step - loss: 0.0375 - accuracy: 0.9843\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 12s 764ms/step - loss: 0.0357 - accuracy: 0.9851\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 11s 729ms/step - loss: 0.0354 - accuracy: 0.9850\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 12s 775ms/step - loss: 0.0354 - accuracy: 0.9850\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 11s 709ms/step - loss: 0.0370 - accuracy: 0.9845\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 12s 763ms/step - loss: 0.0364 - accuracy: 0.9847\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 11s 725ms/step - loss: 0.0355 - accuracy: 0.9850\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 12s 775ms/step - loss: 0.0345 - accuracy: 0.9856\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 11s 722ms/step - loss: 0.0337 - accuracy: 0.9858\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 12s 761ms/step - loss: 0.0351 - accuracy: 0.9851\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 11s 715ms/step - loss: 0.0375 - accuracy: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f2c63f790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjvtjVyz5NPU",
        "outputId": "7eab9fcf-9151-4905-e58c-4ed362721769"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-f7776b2df8647afa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-f7776b2df8647afa\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grzYfTDl5NPU"
      },
      "source": [
        "## C. Run the trained model on test images and save the outputs, and evaluate pixel-level segmentation performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NnjU5WlJ5NPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f760500-0117-4a48-9828-e8182f8fdc77"
      },
      "source": [
        "#Step 1: Run model on test images and save the images\n",
        "#number of test images\n",
        "n_i=len(os.listdir('./Data/cirrus_3/test/Image/'))\n",
        "#Call test generator\n",
        "test_gen = testGenerator('./Data/cirrus_3/test/Image/')\n",
        "#Return model outcome for each test image\n",
        "results = model.predict(test_gen,n_i,verbose=1)\n",
        "#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n",
        "saveResult('./Data/cirrus_3/test/Image/','./Data/cirrus_3/test/pred/',results)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 11s 228ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_185.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_173.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_179.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_183.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_200.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjzAOPuC5NPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690f6bf9-7739-4d1e-8f2c-a8048bdb62dc"
      },
      "source": [
        "#Step 2: Evaluate the predicted outcome\n",
        "gt_path='./Data/cirrus_3/test/GT/'\n",
        "evalResult(gt_path,results)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision= 0.23393743019628788 Recall= 0.7545958191200682 IoU= 0.21477866480188149 acc= 0.9833246866861979 F1= 0.32515481775580896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H59wn0vD5NPV"
      },
      "source": [
        "# Task 2: For unet model definition, vary the following \n",
        "# Tip: (Divide and conquer for solving these tasks at Breakout!):\n",
        "## 1. Kernels (dialated kernels), \n",
        "## 2. Separable filters. Check syntax at: (https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D)\n",
        "## 3. Loss function (to dice coefficient) and rerun whole process. Does it improve test performance?\n",
        "### Enter your results in the table below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9-3kVl45NPV"
      },
      "source": [
        "```\n",
        "U-net Parameters  (cirrus_3)          | Precision|Recall|IoU   |acc   |F1    |\n",
        "-------------------------------------------------------------------------------\n",
        "3x3 kernels, binary cross entropy loss|           |     |      |      |      |\n",
        "------------------------------------------------------------------------------\n",
        "5x5 dilated kernels,cross-entropy loss|           |     |      |      |      |\n",
        "------------------------------------------------------------------------------\n",
        "3x3, depthwise                        |           |     |      |      |      |\n",
        "separable kernels,dice_coef loss      |           |     |      |      |      |\n",
        "------------------------------------------------------------------------------\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx3mZ9kMHwc9"
      },
      "source": [
        "#Step 2: Define the U-net model with dialation rate\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = tf.keras.Input(shape=input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal', dilation_rate=2)(inputs) #dialation_rate=2 etc.\n",
        "    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    #[Try removing BatchNormalization and see performance]\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    \n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    \n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    \n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "   \n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n",
        "    \n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel=keras.models.load_model(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ubiUYtDHaeN",
        "outputId": "be1d39b8-9911-4927-8f39-90b8aed9673f"
      },
      "source": [
        "#Step 2: Initialize the model. Train from scratch!\n",
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 256, 256, 64) 640         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 256)  1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 512)  2048        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 512)  2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 512)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 1024) 4096        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 1024) 9438208     batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 1024) 4096        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 1024) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 128, 128, 128 295040      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 128, 128, 128 147584      conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 256, 256, 128 0           batch_normalization_11[0][0]     \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 256, 256, 1)  3           conv2d_46[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,047,557\n",
            "Trainable params: 31,039,621\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90rDVZsnHaRF",
        "outputId": "b0fed7f1-abb9-4cd9-dc0b-d3f01713ccca"
      },
      "source": [
        "#Step 4: Fit the u-net model\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus3.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1)#callbacks=[tensorboard_callback])\n",
        "# you can load the saved model using:\n",
        "# model.load_weights('unet_cirrus.hdf5')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 13s 724ms/step - loss: 0.5064 - accuracy: 0.9099\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 11s 722ms/step - loss: 0.0972 - accuracy: 0.9503\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 11s 762ms/step - loss: 0.0793 - accuracy: 0.9494\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 11s 756ms/step - loss: 0.0717 - accuracy: 0.9496\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 12s 792ms/step - loss: 0.0705 - accuracy: 0.9504\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 12s 765ms/step - loss: 0.0704 - accuracy: 0.9488\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 12s 767ms/step - loss: 0.0660 - accuracy: 0.9503\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 11s 736ms/step - loss: 0.0662 - accuracy: 0.9493\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 11s 761ms/step - loss: 0.0651 - accuracy: 0.9496\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 11s 742ms/step - loss: 0.0624 - accuracy: 0.9506\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 12s 777ms/step - loss: 0.0636 - accuracy: 0.9483\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 11s 751ms/step - loss: 0.0603 - accuracy: 0.9521\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 12s 778ms/step - loss: 0.0601 - accuracy: 0.9513\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 11s 753ms/step - loss: 0.0660 - accuracy: 0.9485\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 12s 767ms/step - loss: 0.0635 - accuracy: 0.9794\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 11s 743ms/step - loss: 0.0632 - accuracy: 0.9802\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 11s 765ms/step - loss: 0.0616 - accuracy: 0.9807\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 11s 741ms/step - loss: 0.0632 - accuracy: 0.9799\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 12s 767ms/step - loss: 0.0632 - accuracy: 0.9788\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 11s 742ms/step - loss: 0.0605 - accuracy: 0.9798\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 12s 773ms/step - loss: 0.0480 - accuracy: 0.9803\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 11s 749ms/step - loss: 0.0453 - accuracy: 0.9804\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 12s 769ms/step - loss: 0.0449 - accuracy: 0.9810\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 11s 747ms/step - loss: 0.0429 - accuracy: 0.9814\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 12s 766ms/step - loss: 0.0446 - accuracy: 0.9808\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 11s 737ms/step - loss: 0.0474 - accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 12s 770ms/step - loss: 0.0453 - accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 11s 741ms/step - loss: 0.0418 - accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 12s 771ms/step - loss: 0.0443 - accuracy: 0.9809\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 11s 746ms/step - loss: 0.0417 - accuracy: 0.9819\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 12s 771ms/step - loss: 0.0442 - accuracy: 0.9810\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 11s 753ms/step - loss: 0.0395 - accuracy: 0.9831\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 12s 768ms/step - loss: 0.0410 - accuracy: 0.9826\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 11s 752ms/step - loss: 0.0422 - accuracy: 0.9819\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 12s 772ms/step - loss: 0.0396 - accuracy: 0.9828\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 11s 758ms/step - loss: 0.0394 - accuracy: 0.9830\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 12s 775ms/step - loss: 0.0380 - accuracy: 0.9836\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 11s 744ms/step - loss: 0.0369 - accuracy: 0.9841\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 12s 768ms/step - loss: 0.0389 - accuracy: 0.9832\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 11s 746ms/step - loss: 0.0375 - accuracy: 0.9838\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 11s 763ms/step - loss: 0.0358 - accuracy: 0.9846\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 11s 757ms/step - loss: 0.0391 - accuracy: 0.9833\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 12s 767ms/step - loss: 0.0373 - accuracy: 0.9839\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 11s 742ms/step - loss: 0.0357 - accuracy: 0.9847\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 12s 769ms/step - loss: 0.0351 - accuracy: 0.9849\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 11s 738ms/step - loss: 0.0376 - accuracy: 0.9837\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 12s 770ms/step - loss: 0.0360 - accuracy: 0.9845\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 11s 752ms/step - loss: 0.0349 - accuracy: 0.9849\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 12s 777ms/step - loss: 0.0347 - accuracy: 0.9852\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 11s 740ms/step - loss: 0.0347 - accuracy: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f1a363910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uc5qHBZHaiH",
        "outputId": "20c3e340-b33f-440a-bc41-508bd321309e"
      },
      "source": [
        "#Step 1: Run model on test images and save the images\n",
        "#number of test images\n",
        "n_i=len(os.listdir('./Data/cirrus_3/test/Image/'))\n",
        "#Call test generator\n",
        "test_gen = testGenerator('./Data/cirrus_3/test/Image/')\n",
        "#Return model outcome for each test image\n",
        "results = model.predict(test_gen,n_i,verbose=1)\n",
        "#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 2s 33ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd0Rh_7qHal3",
        "outputId": "7b260070-b954-4adb-8295-74432e1cc401"
      },
      "source": [
        "saveResult('./Data/cirrus_3/test/Image/','./Data/cirrus_3/test/pred/',results)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_159.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_163.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_167.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_155.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_166.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_160.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_150.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_164.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_154.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_157.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_153.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_165.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_156.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_180.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_177.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_181.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_186.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_178.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_175.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_184.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_189.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_192.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_176.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_170.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_172.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_174.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_171.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_194.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_169.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_188.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_193.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_190.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_182.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_195.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_185.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_191.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_173.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_179.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_183.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_196.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_199.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:119: UserWarning: ./Data/cirrus_3/test/pred/bscan_200.jpg_predict.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARDfFodOIngo",
        "outputId": "eaa7d7aa-bcac-4403-fe88-4b0e72953362"
      },
      "source": [
        "#Step 2: Evaluate the predicted outcome\n",
        "gt_path='./Data/cirrus_3/test/GT/'\n",
        "evalResult(gt_path,results)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:178: RuntimeWarning: invalid value encountered in true_divide\n",
            "  img1=np.array(((img - np.min(img))/np.ptp(img))>0.1).astype(float)\n",
            "/content/gdrive/MyDrive/Colab Notebooks/unet_helper_functions.py:140: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  prec=tp/(tp+fp)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision= nan Recall= 0.20710662603786736 IoU= 0.13700531191977283 acc= 0.9929599761962891 F1= 0.20241727520915284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDi0oPiQInof"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8NenFilOY7E"
      },
      "source": [
        "#Step 2: Define the U-net model with depth wise layer\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = tf.keras.Input(shape=input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n",
        "    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    #[Try removing BatchNormalization and see performance]\n",
        "    conv1 = DepthwiseConv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = DepthwiseConv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = DepthwiseConv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = DepthwiseConv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = DepthwiseConv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = DepthwiseConv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = DepthwiseConv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = DepthwiseConv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = DepthwiseConv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    \n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    \n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    \n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "   \n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n",
        "    \n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel=keras.models.load_model(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "tbBVmub5Inrs",
        "outputId": "15328930-8fbd-4f0a-af8d-9bc9f94f1f88"
      },
      "source": [
        "#Step 2: Initialize the model. Train from scratch!\n",
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_10/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7bfd71b042cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Step 2: Initialize the model. Train from scratch!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-02d0f998bd46>\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepthwiseConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepthwiseConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   4658\u001b[0m         \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4659\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4660\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, explicit_paddings, data_format, name)\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5343\u001b[0m                    \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5344\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5345\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3563\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3564\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3565\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3566\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3567\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2042\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_10/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoQotGOFInvD"
      },
      "source": [
        "#Step 4: Fit the u-net model\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus3b.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1)#callbacks=[tensorboard_callback])\n",
        "# you can load the saved model using:\n",
        "# model.load_weights('unet_cirrus.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRB-95FgORnZ"
      },
      "source": [
        "#Step 1: Run model on test images and save the images\n",
        "#number of test images\n",
        "n_i=len(os.listdir('./Data/cirrus_3/test/Image/'))\n",
        "#Call test generator\n",
        "test_gen = testGenerator('./Data/cirrus_3/test/Image/')\n",
        "#Return model outcome for each test image\n",
        "results = model.predict(test_gen,n_i,verbose=1)\n",
        "#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p51ng2UoORqX"
      },
      "source": [
        "saveResult('./Data/cirrus_3/test/Image/','./Data/cirrus_3/test/pred/',results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcG4nXR8ORtY"
      },
      "source": [
        "#Step 2: Evaluate the predicted outcome\n",
        "gt_path='./Data/cirrus_3/test/GT/'\n",
        "evalResult(gt_path,results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMVRWVg3RNt8"
      },
      "source": [
        "#Step 2: Define the U-net model Dice coef and loss\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = tf.keras.Input(shape=input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs) #dialation_rate=2 etc.\n",
        "    #[Try DepthwiseConv2D instead of Conv2D for depthwise separable filters]\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    #[Try removing BatchNormalization and see performance]\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)#training=True will enable dropout for test data\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    \n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    \n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    \n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "   \n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'dice_coef_loss', metrics = 'dice_coef')\n",
        "    # Modify loss function above to dice_coef_loss defined above, and metrics to dice_coef\n",
        "    \n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel=keras.models.load_model(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYOK_4CqORwX",
        "outputId": "652281b6-eb54-4911-a89c-04e96f5e94a0"
      },
      "source": [
        "#Step 2: Initialize the model. Train from scratch!\n",
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 256, 256, 64) 640         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 256, 256, 64) 256         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 256, 256, 64) 256         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 128, 128, 64) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 128, 128, 128 512         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 128, 128, 128 512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 64, 64, 128)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 64, 256)  1024        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 64, 64, 256)  1024        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 256)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 512)  2048        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 512)  2048        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 512)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 512)  0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 1024) 4096        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 1024) 9438208     batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 1024) 4096        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 1024) 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 1024) 0           dropout_4[0][0]                  \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_31[0][0]     \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 128, 128, 256 0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 128, 128, 256 0           batch_normalization_29[0][0]     \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 128, 128, 128 295040      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 128, 128, 128 147584      conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_11 (UpSampling2D) (None, 256, 256, 128 0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 256, 256, 128 0           batch_normalization_27[0][0]     \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 256, 256, 1)  3           conv2d_71[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,047,557\n",
            "Trainable params: 31,039,621\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRLqk8dYRh5U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "Gr5zzreQRh2P",
        "outputId": "2ac753f9-f425-4d80-80d5-fd7f09afab13"
      },
      "source": [
        "#Step 4: Fit the u-net model\n",
        "#model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus3d.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1)#callbacks=[tensorboard_callback])\n",
        "# you can load the saved model using:\n",
        "# model.load_weights('unet_cirrus.hdf5')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2645e7c917ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Step 4: Fit the u-net model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_cirrus3d.hdf5', monitor='loss',verbose=1, save_best_only=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#callbacks=[tensorboard_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# you can load the saved model using:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.load_weights('unet_cirrus.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3440\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3441\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3363\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:797 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__\n        self.build(y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:136 build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:867 map_structure\n        structure[0], [func(*x) for x in entries],\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:276 _get_loss_object\n        loss = losses_mod.get(loss)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:2078 get\n        return deserialize(identifier)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:2037 deserialize\n        printable_module_name='loss function')\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:703 deserialize_keras_object\n        .format(printable_module_name, object_name))\n\n    ValueError: Unknown loss function: dice_coef_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZAi5859Rh8T"
      },
      "source": [
        "#Step 1: Run model on test images and save the images\n",
        "#number of test images\n",
        "n_i=len(os.listdir('./Data/cirrus_3/test/Image/'))\n",
        "#Call test generator\n",
        "test_gen = testGenerator('./Data/cirrus_3/test/Image/')\n",
        "#Return model outcome for each test image\n",
        "results = model.predict(test_gen,n_i,verbose=1)\n",
        "#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IjXQ5zIORzt"
      },
      "source": [
        "#Step 2: Evaluate the predicted outcome\n",
        "gt_path='./Data/cirrus_3/test/GT/'\n",
        "evalResult(gt_path,results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAng_K3a5NPW"
      },
      "source": [
        "## Save the model with \"best\" performance above as unet_cirrus3.hdf5 model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42llswV15NPW"
      },
      "source": [
        "# Task 3: Perform transfer learning with 'unet_cirrus3.hdf5' as base weights and retrain on the 'nidek1' data set. Your training should take fewer epochs now. Report performace using 3x3 kernels with cross entropy loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3vr58fB5NPW"
      },
      "source": [
        "### Hint: To load a previously save model that has custom loss functions use the following commands:\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "dependencies = {\n",
        "    'dice_coef_loss': dice_coef_loss\n",
        "}\n",
        "\n",
        "model=load_model('unet_cirrus3.hdf5',custom_objects=dependencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZvsoL_A5NPW"
      },
      "source": [
        "# Task 4: Analyze the importance of BatchNormalization:\n",
        "## For the Nidek1 dataset, remove all BatchNormalization commands and test the model.\n",
        "## Next, add more batch normalizations after each conv2D layer for decoder networks and test the model.\n",
        "## Report how useful Batchnormalization is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij_bvhjMLjy0"
      },
      "source": [
        "# **Summary and Discussion:** **Discuss** \"What would you report back as the BEST method for semantic segmentation?\" \n",
        "# Think in terms of Data, Process and Outcomes specifically.\n",
        "## Consider the following:\n",
        "1. Medical data sets typically require high Recall, since missing data (false negatives) is detrimental. False positives (in terms of low precision) can be tolerated since the therapist/doctor will look at the outcome.\n",
        "2. For semantic segmenation, high IoU and F-1 score is preferred, since it ensures the region of interst (cyst in this case) is well located.\n",
        "3. Accuracy is NOT an important metric in semantic segmentation since false negatives are not that important.\n",
        "4. Medical images are sensitive to training data so picking a represntative tarining data set is cruciual.\n",
        "\n",
        "# Now what method (hyperparameters) results in BEST model. \n",
        "Share screen and discuss findings. Think about generalizability (something that works across data sets).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juI2urH35NPW"
      },
      "source": [
        "## Once you have mastered Binary Semantic Segmentation using U-net, you may consider extensions to multi-class segmentation using the following:\n",
        "## 1. Blog: https://towardsdatascience.com/a-machine-learning-engineers-tutorial-to-transfer-learning-for-multi-class-image-segmentation-b34818caec6b\n",
        "\n",
        "## 2. Video Lecture: https://youtu.be/ihq1Fg-KY5k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh-9zJ2pt5XZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nioO00_mVihZ"
      },
      "source": [
        "|Model type   |Precision   |Recall   |IOU   |ACC   |F1   |\n",
        "|---|---|---|---|---|---|\n",
        "|Base   |0.234   |0.754   | 0.214  |0.983   |0.325   |\n",
        "|Dialeted kernel   |nan   |0.207   |0.137   |0.993   |0.202   |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAWMMZeMWBQ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}